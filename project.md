socket 底层原理

## BDCI
使用mmap读取文件，提高文件速度
是什么：
mmap是一种内存映射技术，他可以将文件物理地址或者其他对象映射到进程的虚拟地址空间，实现虚拟的地址空间和文件磁盘的一一映射，进程就可以像操作内存一样操作磁盘。

具体过程：
+ 进程启动映射过程，在虚拟地址空间中为映射创建虚拟映射区域
+ 调用内核中的系统调用函数mmap，实现文件物理地址和进程虚拟地址的一一映射关系。
+ 当进程发起对映射空间访问的时候，会产生缺页异常，内核请求调页，首先会到swap cache中找寻是否存在对应的页，如果没有的话才调用nopage函数把所缺的页从磁盘装入到主存中。	

为什么更快：
考虑传统的文件IO传输，首先进程发起read系统调用陷入内核，会先在内核缓冲区中寻找是否有该文件，假如找不到的话才会去硬盘找，由DMA会把磁盘的数据通过拷贝到内核缓冲区里面，由于内核空间不能直接被用户进程寻址()，所以CPU必须再把内核缓冲区中的数据拷贝到用户缓冲区中，我们可以发现，这里面文件数据经过了2次拷贝，2次上下文切换，假如文件数据很大的话，就会非常耗时。而通过mmap后，我们可以把文件物理地址与进程的虚拟地址空间映射起来，当我们可以访问进程的地址空间，发生缺页中断，内核开始调页，然后把硬盘文件数据调入物理内存中，这样就只进行了从硬盘到主存的一次拷贝。内存读写取代了I/O读写。

好处：
+ 用内存读写取代I/O读写，提高了文件读取效率。
+ 提供进程间通过共享内存相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的
+ 实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。

void *mmap(void*start, size_t size, int prot, int flags, int fd, off_t offset)

一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。
可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致


+ 使用多线程优化查询速度
+ 两个地方用到了多线程，第一个是在文件读入缓存后，将数据缓存切片32块，32个线程，每个线程读取对应的块并进行二维vector建图，建反向图，但是这里要注意，由于vector写的时候不是线程安全的，所以要用互斥锁。(二维vector建图后转邻接矩阵，边的时间戳从大到小访问，访问内存连续，队友写的）
+ 搜索的时候用到了多线程，首先dfs一遍，求出dfn序列， 缓存局部性原理，友好，把32个线程每32个点出发进行dfs找环，加快访问的速度。

如何继续优化。首先第一个是每个线程dfs的时间不一样，可能有些线程早就结束了，考虑应该申请一个任务等待队列，不断传任务。用队列是否非空的条件变量控制。

for (int i = 0; i < 31; ++i) {
	for (int j = pos[i]; j < pos[i + 1]; ++j) {

	}
}
每个点开个互斥量
mutex[x].lock();
建图
mutex[x].unlock();

+ 
+ （为什么多线程可以加快速度）。

//等待回收
void cal(int i, int j) {

}
thread tid[33](fn, args);
for (int i = 0; i < 10; ++i)
	tid[i] = thread(cal, 1, 10000);
tid[i].join() //阻塞并等待线程结束回收资源。

detach 分离的线程会在调用它的线程结束或自己结束时释放资源

+ std::mutex
```cpp
mutex mtx;
mtx.lock()
do thing
mtx.unlock()

try_lock() //尝试上锁，未被上锁就上锁返回true, 被锁了就返回false
```



如何取舍线程池的数量
高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？

这是我在并发编程网上看到的一个问题，把这个问题放在最后一个，希望每个人都能看到并且思考一下，因为这个问题非常好、非常实际、非常专业。关于这个问题，个人看法是：

（1）高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换

（2）并发不高、任务执行时间长的业务要区分开看：

a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以加大线程池中的线程数目，让CPU处理更多的业务

b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换

（3）并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考（2）。最后，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件对任务进行拆分和解耦。

为什么设置33个线程呢？


1. CPU密集型任务
       要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。

一般配置线程数=CPU总核心数+1    (+1是为了利用等待空闲)

2. IO密集型任务
       这类任务的CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。常见的大部分任务都是IO密集型任务，比如Web应用。对于IO密集型任务，任务越多，CPU效率越高(但也有限度)。

一般配置线程数=CPU总核心数 * 2 +1
最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目

最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目

线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程

32、什么是CAS
CAS，全称为Compare and Swap，即比较-替换。假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功。


技术点（多线程）。
多线程如何合作（问项目）。√

多线程通信方式。
+ 临界区
  多线程通过对共享资源访问进行通信，所以需要通过锁，互斥锁、自旋锁、读写锁。条件变量机制控制。
+ POSIX信号量:有名信号量，无名信号量

+ 信号：	

锁的种类。
各种锁的机制。
多线程和多进程的区别。
线程切换和进程切换的过程和区别。
+ 进程切换要切换虚拟地址空间（导致TLB失效）。
+ 进程和线程都要保存栈、程序计数器、寄存器。
  

如何权衡使用多线程还是多进程。

+ 提出双向搜索思想和哈希集合降低复杂度

因为我们发现，每个点出发正反，最多走3步，必定可以走完环能走的所有的地方。开始走之前，先用unordered_map<int, vector<Edge>> 一个节点存下反向走的长度为0， 长度为1， 长度为2的，长度为3的边, a->b, b->c, c->st。只需要判断连接的这条边是否满足时间戳和花费，满足的话就把答案记录下来。

哈希集合





## 简易的linux socket聊天室
这是linux系统下一个简易的用socket实现的聊天室
主要采用C/S模式，基于socket编程，实现各个客户端之间的正常通信，服务器端使用sqlite数据库存储用户数据

+ 实现了用户注册，登录功能。
+ 实现了用户间公聊、私聊功能。
+ 实现离线上线提示。

+ 客户端使用两个线程保证键盘读入与读入同时进行

1.统一定义了通信格式
里面cmd表示功能，state表示请求的响应状态，name标识用户，data传输的数据
(宏定义完成)

#define BROADCAST 0X00000001   //广播数据
#define PRIVATE 0X00000002     //私聊
#define REGISTE 0X00000004     //注册账号
#define LOGIN 0X00000008       //登录
#define ONLINEUSER     0X00000010 //显示在线用户
#define LOGOUT     0X00000020    //退出
								//在线查看聊天记录
								//注册登录

state
#define OP_OK    0X80000000         //操作成功
#define ONLINEUSER_OK    0X80000001  //显示在线用户，未结束
#define ONLINEUSER_OVER  0X80000002  //显示在线用户，已经发送完毕
#define NAME_EXIST 0X80000003       //注册信息，用户名已经存在
#define NAME_PWD_NMATCH 0X80000004 //登录时，输入的用户名密码不对
#define USER_LOGED 0X80000005     //登录时，提示该用户已经在线
#define USER_NOT_REGIST 0X80000006  //登录时，提示用户没有注册

2.多线程服务器模型
用使用线程池预先创建线程，优化了处理效果。

为什么使用多线程呢？

什么是线程池，线程池具体怎么实现的。
线程池就是预先创建一些线程，当任务来的时候提交给线程池，再去线程池寻找空闲线程来执行任务，线程运行完后，还会复用线程。

线程池分为三个部分
任务定义
struct task{
	(void*)(*function)(void*);//不同任务类型的函数指针
	void *arg;//任务参数
}
管理者线程，线程数组，任务队列。

线程池中存储线程的核心线程数、最大线程数、正在工作线程数。
还有一个任务队列存储任务，队列最大任务数，队列当前任务数。

+ 初始化线程池
创建任务队列，线程数组，初始化参数，初始化互斥量，条件变量pthread_cond_init，启动工作线程和管理者线程。

+ 工作线程实现
条件变量可以根据某个条件的发生控制线程的阻塞与运行。搭配互斥锁使用。

while (true) {
	pthread_mutex_lock(&(pool->lock));
	while (pool->queue_size == 0) {
		pthread_cond_wait(&(pool->queue_not_empty),&(pool->lock));
		//条件未发生，先解锁并阻塞（加入到条件等待队列中）。
		条件发生后被唤醒，唤醒后，锁定mutex。
	}
}
否则取出任务
pthread_cond_broadcast(&(pool->queue_not_full));//广播可以添加新任务
//释放线程锁
    pthread_mutex_unlock(&(pool->lock));
执行任务
(*(task.function))(task.arg)

+ 向线程池的任务队列中添加一个任务。
  threadpool_add_task();
  while (pool->queuesize == max) {
	  pthread_cond_wait(&(pool->queue_not_full), &(pool->lock));
  }
  加任务
  pthread_cond_signal(&(pool->queue_not_empty()));
  pthread_mutex_unlock(&(pool->lock))



**为什么用线程池。**
+ 线程是稀缺资源，使用线程池可以减少创建和销毁线程的次数，复用多个工作线程。
+ 可以根据系统的承受能力，调整线程池中工作线程的数量，防止因为消耗过多内存导致服务器崩溃。

还能怎么优化。
+ 多线程抢锁开销，考虑多个任务队列，减小锁的粒度
+ 发送信息的时候，记录时间戳，只发送部分改变的地方


条件变量
pthread_cond_init();
pthread_cond_wait();
//发送一个信号给至少一个正在等待该条件变量的人，唤醒。
pthread_cond_signal(&(pool->queue_not_empty()));
pthread_cond_broadcast
pthread_mutex_unlock();

while(){
	//因为只有一个人可以获得这个互斥所，所以要睡觉。	
	pthread_cond_wait()
}

**pthread_cond_wait 为什么需要传递 mutex 参数？**

结论：以免出现唤醒丢失问题
这里的关键在于：将线程加入唤醒队列后方可解锁。操作是原子的。
保证了线程还没有真正放到阻塞队列时，线程 B 不能修改“条件”后进行唤醒。

惊群问题是计算机科学中，当许多进程等待一个事件，事件发生后这些进程被唤醒，但只有一个进程能获得CPU执行权，其他进程又得被阻塞，这造成了严重的系统上下文切换代价。

管理者线程定时管理
+ 假如当前任务队列中任务数量 > 最小正在等待的任务数量， 且存活数 < 最大线程数，增加默认大小线程
+ 减少线程，假如当前繁忙线程 < 一半的存活线程，且存活的大于最小线程数，销毁defalut
怎么销毁呢，通过正在等待队列非空条件变量提醒，有一个待销毁线程。

4核8线程，考虑到处理的是IO密集型任务，所以初始化核心线程为16线程，等待队列100个线程。最大值数32线程。原来的四倍。任务队列是线程数的4倍。

总体信息
线程池状态信息：描述当前线程池的基本信息，如是否开启、最小线程数、最大线程数、存活线程数、忙线程数、待销毁线程数等… …
任务队列信息：描述当前任务队列基本信息，如最大任务数、队列不为满条件变量、队列不为空条件变量等… …
多线程互斥锁：保证在同一时间点上只有一个线程在任务队列中取任务并修改任务队列信息、修改线程池信息；
函数指针：在打包消息阶段，将分类后的消息处理函数放在(*function);
void*类型参数：用于传递消息处理函数需要的信息；

