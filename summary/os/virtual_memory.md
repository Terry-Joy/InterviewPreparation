## 虚拟内存
虚拟内存是一种内存管理机制，由于程序很多都大于现在计算机内存容量，所以采取将程序分块存储的方式，但对于程序员来说管理这些是非常复杂且容易出错的。虚拟内存就出现了，它的本质是对于每一个程序，抽象出一个属于自己的连续的虚拟地址空间，该地址空间被分割成多个块，每页都有连续的地址范围，有些页被映射到实际的物理内存上，有些页存储在硬盘上，在需要的时候进行内存交换。这种抽象使得程序只需要关注自己的虚拟地址空间即可。

## 分页机制
[![bwYGdK.png](https://s4.ax1x.com/2022/03/05/bwYGdK.png)](https://imgtu.com/i/bwYGdK)

进程访问的地址被称为“虚拟地址”，也就是逻辑地址，它由页号和偏移量组成。页号用于索引页表中的页表项。页表项中存储的就是实际的物理内存中的页框号，偏移量指明了一个地址单元在实际的物理页中的位置，假设一个页大小为4KB，那么偏移量就需要占用12位，因为212=4096。

分页机制存在两个问题：
+ 虚拟地址到物理地址的映射速度
+ 每个进程都有自己的页表，页表大小太大了，内存装不下

⻚表是存储在内存⾥的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的⼯作。

**解决第一个问题**

**局部性原理**：
局部性原理就是说一个进程在一段时间内对程序指令和数据的引用通常倾向于在一个紧凑的范围内，举个例子，如果使用分页机制，那么在一段时间内它就总是访问那几个页，这也是虚拟内存机制比较实用的原因之一，因为我们我们最近加载进内存的那些页是程序在最近经常访问的页的概率很高。

**TLB**：
转换检测缓存区（快表）：是一个高速缓存，一般保存在MMU中，用于保存最近使用过的页表项目，访问很快，有虚拟页面号、有效位、对应物理页框号等。


分页虚拟地址映射过程:
[![bwJHxA.png](https://s4.ax1x.com/2022/03/05/bwJHxA.png)](https://imgtu.com/i/bwJHxA)

+ 虚拟地址放入MMU的转换的时候，首先匹配TLB表项查找是否有对应的虚拟页面，若找到了有效匹配且访问不违反保护位，取出页框号获取物理地址。
+ TLB找不到，进程使用页表寄存器找到页表对应的物理地址
+ 使用虚拟地址前n位的页号到页表中查找对应页表项，得到页框号
+ 使用页框号去内存中索引对应页框 
+ 使用偏移量确定具体该读取该页中的哪个字节
+ 假如找到了且就直接拿出来用(TLB找不到的话还要更新TLB)
+ 内存中找不到的话就从硬盘中取出，看内存是否满了，未满直接放入，满了就交换最少使用的页

**解决第二个问题**

**多级分页机制**
将一个进程的页表完全存储在内存中是不太可行的。采用多级页表机制。上一级的页表项中存储的是下一级页表的地址。实际上并不是每个页表都要开辟的，很可能只有部分二级页表存在（需要时再创建）。

[![bwaIc4.png](https://s4.ax1x.com/2022/03/05/bwaIc4.png)](https://imgtu.com/i/bwaIc4)

## 分段机制
原因：
为了使程序和数据被划分为逻辑上独立的地址空间并且有助于共享和保护。

分段就是把内存看成多个不固定大小且动态的用户可见的段组成的，每个段都是独立的地址空间，一般是按过程划分的，比如堆栈段，数据段。这是一种二维的线性虚拟空间，以段为单位分配内存，然后通过地址映射机构把段式虚拟地址转换为实际内存物理地址。

**优点**：
+ 简化对不断增长的数据结构的管理。
+ 程序可以分别编写与编译
+ 有助于进程间的共享，比如可以在某个段中放置共享数据和工具（共享库）由各个进程共享，就不用每个进程都写入了。
+ 不同的段可以用于区分不同的过程和数据，从而可以有不同种类的保护。

**缺点**
会产生内存碎片。浪费很多内存，同时进行频繁的内存交换，会使系统变得卡顿。

[![b09Iuq.png](https://s4.ax1x.com/2022/03/05/b09Iuq.png)](https://imgtu.com/i/b09Iuq)

## 段页式管理
+ 先将程序划分为多个有逻辑意义的段，也就是前⾯提到的分段机制；
+ 接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚(无法存入整个段，所以分页。)
将段的优点和页的优点结合。
缺点：由于管理软件的增加，复杂性和开销也增加。另外需要的硬件以及占用的内存也有所增加，使得执行速度下降。

[![b0CwIU.png](https://s4.ax1x.com/2022/03/05/b0CwIU.png)](https://imgtu.com/i/b0CwIU)