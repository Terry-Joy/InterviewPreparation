## 1.OSI七层模型及其主要功能
[![Hj86ud.png](https://s4.ax1x.com/2022/02/21/Hj86ud.png)](https://imgtu.com/i/Hj86ud)

+ 应用层：为用户的应用进程提供网络通信服务。在互联网中的应用层协议很多，如域名系统DNS、HTTP协议、FTP, SMTP协议等。
+ 表示层：处理用户信息的表示问题，数据的编码，压缩和解压缩，数据的加密和解密
+ 会话层：负责在网络中的两节点之间建立、维持和终止通信
+ 传输层：负责向两台主机进程之间的通信提供数据传输服务。传输层的协议主要有传输控制协议TCP和用户数据协议UDP。
+ 网络层：选择合适的路由和交换结点，确保数据及时传送。主要包括$IP,ICMP$协议。
+ 数据链路层：在两个相邻节点之间传送数据时，数据链路层将网络层交下来的$ IP$ 数据报组装成帧，在两个相邻节点间的链路上传送帧。
+ 物理层：实现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和物理设备的差异。

TCP/IP 四层模型
+ 应用层：为用户的应用进程提供网络通信服务。FTP协议，HTTP协议，SMTP，DNS等
+ 传输层：负责为端到端的主机进程之间提供数据传输服务。传输层的协议主要有传输控制协议TCP和用户数据协议UDP。
+ 网络层：选择合适的路由和寻址，确保数据及时转发。IP,ICMP协议。
+ 网络接口层：实现网卡接口的网络驱动程序，以处理数据在物理媒介上的传输。主要有ARP、RARP协议。


## 2.ARP协议及其工作原理
### ARP协议
在网络层上方使用$IP$地址标识主机，但在数据链路层我们需要用知道主机的硬件地址(MAC地址)。

ARP是IPv4协议中实现从$IP$地址向物理地址的动态映射。(IPv6 使用邻居发现协议，ICMPv6中)

### ARP协议工作原理
每台主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址的对应关系。
+ 当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP列表中是否存在该 IP地址对应的MAC地址，如果有，就直接将数据包发送到这个MAC地址；如果没有，就向本地网段发起一个ARP请求的广播包，(ff:ff:ff:ff:ff:ff), 查询此目的主机对应的MAC地址。此ARP请求数据包里包括源主机的IP地址、硬件地址、以及目的主机的IP地址。
+ 网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的MAC地址和IP地址添加到自己的ARP列表中，如果ARP表中已经存在该IP的信息，则将其覆盖，然后给源主机发送一个 ARP响应数据包，告诉对方自己是它需要查找的MAC地址。
+ 源主机收到这个ARP响应数据包后，将得到的目的主机的IP地址和MAC地址添加到自己的ARP列表中，并利用此信息开始数据的传输。
+ 如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。
(如果本地网段无法查询，则通过网关路由表向外查询)#

## 3.RARP协议及其工作原理

反向地址转换协议，网络层协议，RARP与ARP工作方式相反。 RARP使只知道自己硬件地址的
主机能够知道其IP地址。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所
需信息的RARP服务器发出的IP地址。
原理：
(1)网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网
卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求**RARP服务器**回复该主机的
IP地址。
(2)RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP响应发送给主机。
(3)PC1收到RARP回应后，就使用得到的IP地址进行通讯。

## 4.简述DNS
DNS是域名系统，是一个分布式的数据库。用于将主机名和域名转换为$IP$地址的工作。
DNS采取树状层次域名结构，分级自上而下分别为根域名、顶级域名、二级域名、三级域名。
域名服务器自上而下分为根域名服务器，顶级域名服务，权限域名服务器。

## 5.DNS解析过程
+ 从浏览器缓存中查找，找到直接返回IP
+ 没有，找操作系统hosts文件和本地DNS解析器缓存
+ 仍没有，就将域名发送到本地域名服务器(由ISP管理)去请求，这个过程也就是"递归查询"，本地域名服务器查询自己DNS缓存寻找对应域名，(多级缓存机制，从www.baidu.com -> com，没问到别答)，有就返回，都没有依次就向根域名服务器，顶级域名服务器，权威域名服务器进行迭代查询。（本地DNS服务器通过端口53）具体来讲就是根服务器查询对应域名有IP地址，若有就返回IP，否则就返回对应下一级域名服务器的地址，本地域名服务器会继续查询，以此类推，最后返回IP地址给本地域名服务器
+ 本地域名服务器缓存该IP地址和域名，同时返回IP地址给主机
+ 主机操作系统将IP返回给浏览器
+ 浏览器得到域名对应IP地址并缓存

**UDP传输**

## 6.谈谈你对域名缓存的了了解？
DNS服务器上使用高速缓存，⽤来存放最近查询过的域名以及从何处获得域名映射信息的记录。本质是为了提⾼ DNS 查询效率，减轻服务器的负荷和减少因特⽹上的 DNS 查询报⽂。由于名字到地址的绑定并不经常改变，为保持⾼速缓存中的内容正确，域名服务器应为每项内容设置计时器并处理超过合理时间的项。当域名服务器器已从缓存中删去某项信息后⼜被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权威服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少⽹网络开销，⽽而减少此时间值可提⾼高域名解析的正确性。
不仅在本地域名服务器中需要⾼高速缓存，在主机中也需要。许多主机在启动时从本地服务器下载名字和地址的全部数据库，维护存放⾃己最近使用的域名的⾼速缓存，并且只在从缓存中找不不到名字时才使⽤域名服务器器。维护本地域名服务器数据库的主机应当定期地检查域名服务器以获取新的映射信息，⽽且主机必须从缓存中删除无效的项。
由于域名改动并不不频繁，⼤多数网点不不需花精力就能维护数据库的⼀致性。

## IP协议相关
+ ip地址分类
+ ip地址和mac地址区别
+ 子网划分、子网掩码
+ ICMP协议
+ 局域网、广域网

## 7.TCP三次握手
[![bP8YCj.png](https://s4.ax1x.com/2022/02/23/bP8YCj.png)](https://imgtu.com/i/bP8YCj)
TCP是面向连接的协议，一方向另一方发送数据之前，都必须先在双方间建立一条连接。
+ 开始，客户端和服务端都处于 CLOSED 状态。先是服务端监听某个端口，处于 LISTEN 状态
+ **第一次握手**：客户端会随机初始化序号（ client_isn ），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。
+ **第二次握手**, 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（ server_isn ），将此序号填入TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1 , 接着把 SYN和 ACK 标志位置为 1 。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。
+ **第三次握手**，客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。
+ 服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。

**（ISN）是固定的吗**
三次握⼿的⼀个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以让对⽅知道接下来接收数据的时候如何按序列号组装数据。如果ISN是固定的，攻击者很容易易猜出后续的确认号，因此 ISN 是动态⽣生成的
**（1）什么是半连接队列** （SYN queue, accept queue)
TCP三次握手时，linux内核维护两个队列
+ 半连接队列
+ 全连接队列
服务器第⼀次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双⽅还没有完全建⽴其连接，服务器会把此种状态下连接放在一个队列里，我们把这种队列称之为半连接队列。当完成三次握手时，会把半连接队列中的TCP信息放入全连接队列中，如果队列满了了就有可能会出现丢包现象。

**（2）SYN-ACK 重传次数的问题：**
服务器发送完SYN－ACK包，如果未收到客户确认包，服务器进⾏首次重传，等待一段时间仍未收到客户确认包，进⾏第⼆次重传，如果重传次数超过系统规定的最⼤重传次数，系统将该连接信息从半连接队列中删除。每次重传的时间间隔不同的，linux下默认5次，1，2，4，8，16，再等32秒，总共63秒断开。

**（3）三次握⼿手过程中可以携带数据吗**
第三次握⼿手的时候，是可以携带数据的（RFC标准）。假如第一次可以携带，在SYN报文中放入大量数据，攻击服务器，不安全。⽽对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据⻚没啥⽑病。	

**（4）为什么不能两次握手解决**
1.防止重复的已经失效的历史连接的初始化，节省资源。假如只有两次握手，客户端之前发送的一个网络包由于延迟未到达，客户端重传新的SYN报文并完成了连接与传输数据的过程，进入closed状态，这时旧的连接到达服务器，由于只用两次握手，服务器就会发出确认，并且建立连接，但是客户端不理睬他，服务器一直等待客户端数据，浪费了资源。
2.同步双方初始序列号，保证可靠传输。序列号是可靠运输的关键因素，可以让接收方去除重复的数据，按序接收数据包，知道已经发出去的数据包，哪些被收到了。假如是两次握手，第二次握手确认了服务器端知道了客户端的初始序列号，而我们还需要一次握手，表明客户端确认了服务器初始序列号。

**（5）四次握手**
三次握手已经保证了理论上最少可靠连接建立，所以不需要使用更多的通信次数。

**SYN攻击**
TCP连接建立靠的是三次握手，假设攻击者短时间伪造不同IP地址的SYN报文，只发送SYN报文，不应答，服务端每收到一个SYN报文，就会进入SYN_RCVD状态，最后这些SYN报文填满半连接队列，占用大量资源，使得服务器无法正常为用户服务。

**抵御SYN攻击的方法**
增大半连接队列（调整内核参数）
开启tcp_syncookies功能


全连接队列满的时候应该是默认丢弃ACK包的。
半连接队列满的时候除了丢弃，还可以开启SYN cookie, 服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。


## 8.TCP四次挥手
[![bP8N2n.png](https://s4.ax1x.com/2022/02/23/bP8N2n.png)](https://imgtu.com/i/bP8N2n)
刚开始两者都在established状态，
+ 第一次挥手：假如当客户端想关闭连接的时候，发送一个FIN报文给服务器端，同时指定自己的序号，然后进入FIN_WAIT1状态。
+ 第二次挥手：服务器接收到FIN报文后，发送一个ACK报文给客户端，同时指明自己的序列号，还指明自己的确认序列号为客户端序列号+1，发送后进入close_wait状态。
+ 在close_wait状态下，服务器仍能发送数据给客户端，直到所有数据传输完成，服务器端想关闭连接了，第三次挥手：发送一个FIN报文给客户端，且指定一个序列号，此时服务器进入Last_ACK状态。
+ 第四次挥手：客户端受到FIN报文段后，发送一个ACK报文段，确认序列号为服务器序列号+1，然后进入TIME_WAIT状态。
+ 服务器收到ACK报文段之后，进入CLOSED状态，服务器端连接完成关闭
+ 客户端经过2MSL一段时间后，进入CLOSED状态，客户端连接完成关闭

【注意是：主动关闭连接的，才有 TIME_WAIT 状态。】

**为什么要四次**
TCP连接是全双工的也就是说接收到FIN只是说没有数据再发过来但是还是可以发送数据的，也就是接受到一个FIN只是关闭了一个方向的数据传输，另一个方向还可以继续发送数据。在四次挥手的时候也是这样前两次挥手只是确认关闭了一个方向的数据，加上后面两次挥手才真正的关闭了整个全双工连接。

## 9.讲述下TIME_WAIT状态
TIME_WAIT状态有两个作用，
+ 用于确认客户端对服务器FIN报文的确认是否被服务器接收，使得连接正确关闭。等待时间是2MSL，即2个报文最大生存时间，，假如网络环境不好，客户端ACK发送到服务器端是1MSL，服务器端没收到触发超时重传机制重新发送FIN报文段，也是一个MSL，所以来回两个MSL，假如客户端在2MSL过程中没再收到服务器端的信息，说明服务器端已经收到了客户端的确认报文段，则客户端连接可以关闭。
+ 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文,假如相同端口的TCP连接被复用后，旧的数据包可能被接收导致数据错乱。

在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。
**TIME_WAIT时间过长过短的问题看**
https://www.zhihu.com/question/271701044/answer/1279809269


**追问：TIME_WAIT 过多有什么危害**？
过多的 TIME-WAIT 状态主要的危害有两种：
第一是内存资源占用；
第二是对端口资源的占用，一个 TCP 连接⾄少消耗⼀个本地端口（端口65536个）



**TTL与MSL**
MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。

## 10.谈谈你对流量控制的理解
TCP提供流量控制服务，为了防止因为发送方发送速率过快导致接收方缓存溢出，（速度匹配，使发送速度和接收速度匹配）。流量控制是通过滑动窗口机制实现的，接收方和发送方都维护一个接收窗口，对于接收方来说，要保证最后一个从缓存中读出的字节减去已放入接收缓存的最后一个字节的大小要小于等于接收方的缓存大小，缓存减去已用的缓存空间剩余的就是接收窗口的大小，接收方会定期把接收窗口的大小写入报文段中发给发送方，告诉发送方还有多少可用空间，发送方要做得就是保证最后一个发送的字节编号减去最后一个发送的被确认的编号的大小要小于等于接收方的接收窗口。当接收窗口大小为0时，发送方还会发送一个只有一个字节数据的报文段，**（防止死锁，接收方只有有数据或者是确认报文段发送时才会告诉接收方）**，接收方会清空缓存并且返回一个确认报文段携带新的接收窗口大小给发送方。
滑动窗口为大小为0时，发送方不再发送数据，但有两种情况例外
+ 一种情况是可以发送紧急数据。例如，允许用户终止在远端机上的运行进程。
+ 另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

## 11.谈谈你对拥塞控制的理解
网络中出现拥堵时，如果继续发送大量数据包，可能会丢包、超时重传，导致网络的负荷更重，拥塞控制就是通过控制发送方速率，防止过多的数据注入网络中，加重网络的负载。拥塞控制机制中，TCP发送方会维护一个拥塞窗口，该窗口的大小取决于网络的拥塞情况动态变化，发送方的发送窗口取为拥塞窗口和接收方接受窗口中较小的一个。（超时重传 or 三个冗余ACK表示拥塞）。	

TCP拥塞控制采用了四个算法，慢启动，拥塞避免，快速重传和快速恢复算法。
+ 慢启动
  + 慢启动就和其名字一样，一开始不了解网络中的拥塞情况，所以每次一点点地提速试探网络的承受能力
	（1）首先先初始化拥塞窗口大小为一个MSS。
	（2）每收到一个新的ACK，窗口大小加一，线性上升。
	（3）每当过去一个RTT时，窗口大小翻倍。
	所以在慢启动阶段窗口大小几乎成指数递增，但是我们有一个慢启动的阈值，只有窗口大小小于这个阈值的时候，才采取慢启动算法。当窗口大小>=阈值的时候，就会采取拥塞避免算法。

+ 拥塞避免
  + 拥塞避免算法是为了避免窗口增长过快导致网络阻塞，所以每过一个RTT，拥塞窗口的大小才加1，慢慢调整到网络的最佳值。

一般TCP会把丢包认成是网络拥塞的标志，所以当丢包出现的时候，TCP拥塞控制算法会以丢包作为进入拥塞控制的信号，但是丢包一般有两种常见信号：
  + 超时重传，即发送方发送数据后开启定时器，若定时器结束前仍没收到ACK报文，就重新发送。对于这种情况，不管是在拥塞避免状态还是慢启动状态，都会将慢启动阈值设为当前拥塞窗口的一半，然后把拥塞窗口的大小设为1，然后进入慢启动状态。之所以这么做，是因为TCP认为在超时重传的情况下，网络的拥塞状况已经很严重了，需要迅速减少发送到网络中的数据包的数量，使得网络能够有时间把积压的数据包处理完毕。
  + 收到三个冗余的ACK信号，在这种情况下，发送方采取快速重传和快速恢复算法，用于迅速重发丢失的报文段。发送方会把拥塞窗口和慢启动的阈值都变为原来的一半，同时重传冗余ACK指定的数据包，然后进入快速恢复阶段。在快速恢复阶段，如果继续收到冗余的ACK，拥塞窗口会增加一个MSS，最终当丢失的报文段的一个ACK到达时，TCP会把拥塞窗口大小设为慢启动阈值，进入拥塞避免状态。在这阶段假如又出现超时，就会和之前处理方式一样。

## 重传机制

MSS,MTU,MSL

## 12.什么是粘包与拆包问题？
TCP是面向字节流的协议，把上层数据看成是字节流，所以他发送的不是固定大小的数据包，而且TCP报文段中也没有字段说明发送数据包的大小。所以实际上TCP并不知道上层业务数据的具体含义，他是根据TCP缓冲区的实际情况来进行包的划分，可能由于缓冲区过大选择将多个数据包合并在一起发送，也可能由于缓冲区过小只能把数据包拆开分开几次发送，这就是所谓粘包和拆包问题。

## 13.TCP粘包和拆包的原因？
+ 发送方
  + 粘包：要发送的数据包很小，小于TCP缓冲区的大小，TCP将多个写入缓冲区的数据合并在一起，一起发送出去，这就产生了粘包。
  + 拆包：假如要发送的数据包大于TCP发送端缓冲区，或者大于MSS的大小，就会产生拆包，分开几次发送。
+ 接收方：
  + 粘包:因为接收方采用TCP接收数据时的过程是：数据到达接收方，从网络模型下方到达传输层，然后会把其放置在接收缓冲区，由应用层主动获取（read,recv）。假如应用从缓冲区中读取数据的速度慢于数据到达缓冲区的数据，下次就可能出现一次取出多个数据包，产生粘包的现象。
  + 拆包:

## 14.怎么解决粘包和拆包？
+ 把每个数据包封装成固定包长（不够的用0填充）。这样接收端从缓冲区中读取固定长度的数据，自然而然地把数据包拆开了。
+ 在数据包之间设置边界，比如可以在消息末尾处可以通过特殊字符分隔开两个数据包。
+ 将消息分为消息头和消息尾两部分，消息头指定数据长度，根据消息长度来读取完整的消息，例如UDP协议是这么设计的，用两个字节来表示消息长度，所以UDP不存在粘包和拆包问题。

## 15.TCP是怎么保证可靠运输的？
+ 数据包校验和：通过校验和字段，接收方计算校验和，检测数据在传输过程中是否出错，若出错，就丢弃该包等待发送方重传。
+ 序列号同步机制：TCP传输的时候将每个字节的数据都进行了编号，接收方可以根据序列对数据进行排序，同时可以去除重复数据。
+ 确认机制：假如接收方接收到报文段就会发送一个ACK报文段告诉发送方是否收到了该数据。
+ 连接管理：三次握手与四次挥手：通信前确认了通信实体存在,说明连接通道是可用的.
+ 超时重传机制：当TCP发出一个报文段后，会启动一个定时器，等待目的端确认这个报文段，如果不能及时收到这个确认的报文段，对刚才发送的数据进行重传。（翻倍）
+ 流量控制：TCP双方维护一个缓冲区，为了防止发送方发送速率过快导致接收方缓存溢出，通过维护可变大小的滑动窗口实现流量控制机制，接收方告诉发送方接收方剩余缓存的大小从而控制发送方发送速率.
+ 拥塞控制：具体看上方

## 16.TCP的主要特点是什么？
1. TCP 是面向连接的。必须通过三次握手先建立连接，数据传输完毕后还要通过四次挥手释放连接。
2. 每一条 TCP 连接只能有两个端点，每一条 TCP 连接只能是点对点的。
3. TCP 提供可靠交付的服务。通过 TCP 连接传送的数据，⽆差错、不丢失、不重复、并且按序到达；
4. TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，⽤来临时存放双⽅通信的数据；
5. ⾯向字节流。虽然应用程序和TCP交互是一个一个数据块的，但是TCP是把数据按照字节编序号的，他仅把数据看成是一连串无结构的字节流。

## 17.TCP和UDP的区别？
+ TCP面向连接；UDP是无连接的，即发送数据之前不需要建立连接。由于UDP不用建立连接，所以UDP的时延要比TCP小，此外，UDP不用维护连接所需的状态，比如序号、确认号等问题。
+ TCP提供可靠的服务，保证不丢失、无损、按序到达；UDP不保证可靠交付。
+ TCP面向字节流，把数据看成一连串无结构的字节流，所以会有粘包问题。而UDP是面向报文的，以报文段作为单位，所以不会有粘包问题。
+ TCP有拥塞控制和流量控制机制；UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低，所以UDP适用于实时应用，如实时视频会议等）。
+ 每一条TCP连接只能是一对一的；UDP支持多播广播等一对多，多对多方式。
+ TCP首部开销20字节；UDP的首部开销小，只有8个字节。

## 18.HTTP常见状态码？
1xx
1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际⽤到的⽐较少。
2xx
2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。
3xx
3xx 类状态码表示客户端请求的资源发送了变动，需要客户端⽤新的 URL 重新发送请求获取资源，也就是重定向
4xx
4xx 类状态码表示客户端发送的报⽂有误，服务器⽆法处理，也就是错误码的含义。
5xx
5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发⽣了错误，属于服务器端的错误码。


[100 Continue]
该状态码说明服务器收到了请求的初始部分，并且请客户端继续发送。在服务器发送了 100 Continue 状态码之后，如果收到客户端的请求，则必须进行响应。
「200 OK」是最常⻅的成功状态码，表示⼀切正常。如果是⾮ HEAD 请求，服务器返回的响应头都会有 body 数
据。
「204 No Content」也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
「206 Partial Content」是应⽤于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽
是其中的⼀部分，也是服务器处理成功的状态。
「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改⽤新的 URL 再次访问。(会缓存)
「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要⽤另⼀个 URL 来访问。（不会缓存）
301 和 302 都会在响应头⾥使⽤字段 Location ，指明后续要跳转的 URL，浏览器会⾃动重定向新的 URL。
「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲⽂件，也称缓存重定向，⽤于缓
存控制。
「400 Bad Request」表示客户端请求的报⽂有错误，但只是个笼统的错误。
「403 Forbidden」表示服务器禁⽌访问资源，并不是客户端的请求出错。
「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以⽆法提供给客户端。
「500 Internal Server Error」与 400 类型，是个笼统通⽤的错误码，服务器发⽣了什么错误，我们并不知道。
「501 Not Implemented」表示客户端请求的功能还不⽀持，类似“即将开业，敬请期待”的意思。
「502 Bad Gateway」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器
发⽣了错误。
「503 Service Unavailable」表示服务器当前很忙，暂时⽆法响应服务器，类似“⽹络服务正忙，请稍后重试”的意
思。

## 19.讲讲get和post的区别
1.get一般用于检索和获取数据，而post一般用于提交和修改数据。

2.get请求的数据一般放在url上，用?分割URL和传输数据，参数间用&相连，而post一般将数据放在请求体里面提交。

3.由于get用于获取资源，而一般资源不会变动太快，所以get请求一般会被浏览器缓存，而post请求提交数据表单，所以大多数情况下post请求不能被缓存。（请求HTTP方法可以缓存，响应报文的状态码可缓存（200，203....）,响应报文的Cache-Control首部字段没有指定不进行缓存）

4.get操作具有**幂等性**，即同样的请求被执行一次与连续执行多次影响的相同，不管多少次get请求返回的资源都一样，所以get显然是幂等，但post请求是非幂等的，比如每次增加一个数据项，多次就是多个数据项。

5.get在浏览器回退的时候是无害的，而post会再次提交请求。
6.GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留

（这里来扯出幂等主要是为了处理同一个请求重复发送的情况，假如在请求响应之前失去连接，如果这个请求时幂等的，那么就可以放心的重发一次请求。所以可以得出get请求时幂等的，可以重复发送请求，post请求时不幂等的，重复请求可能会发生无法预知的后果。）

## 20.HTTP1.0，1.1，2.0的区别
+ HTTP1.0
HTTP1.0使用的是短连接，浏览器每次请求都需要与服务器建立一个TCP连接，服务器处理完请求后得断开TCP连接，所以每个TCP连接只能发送一个请求，再次发送请求需要重新三次握手建立连接，十分耗时，所以HTTP1.0性能较差

+ HTTP1.1
（1）HTTP1.1相比HTTP1.0使用了长连接，TCP连接默认不关闭的，一个连接可以被多个请求复用，减少了性能开销。
（2）引入了管道机制，在同一个连接中，只要第一个请求发出去了，不必等到确认，就可以发送第二个请求，减少了整体响应时间。
（3）host字段
在HTTP1.0中为每台服务器绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但是随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚机主机，并且它们共享一个IP地址。

HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域，会报400 Bad Request错误。

（4）引入更多缓存控制策略
在HTTP1.0中主要使用header里的If-Modified-Since，Expires来做为缓存判断的标准。

HTTP1.1则引入了更多的缓存控制策略例如If-Unmodified-Since(只有当资源在指定的时间之后没有进行过修改的情况下，服务器才会返回请求的资源，或者是接受其他请求方法。), If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

（5）带宽优化
HTTP1.0中存在一些浪费带宽的现象，例如：（1）客户端只需要某个对象的一部分，而服务器却将整个对象发送过来；(2)下载大文件不支持断点续传功能，在发生断连后需要重新下载完整的包。
HTTP1.1则在请求头中引入range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

(6) 加了很多请求方法，put，delete, options	

但HTTP1.1仍有一些性能可以优化的地方。
+ 请求响应Header未经压缩就发送，header信息越多延迟越大。
+ 服务器是按顺序响应请求，如果服务器前面的请求响应慢，会导致客户端一直请求不到数据，导致队头阻塞。



+ HTTP2
1.头部压缩：同时发出多个请求，头部是一样的，协议会消除重复部分。通过HPACK算法，在客户端和服务器端同时维护一张头信息表，所有字段都存入该表，生成一个索引号，以后不发送相同字段只发送索引号，这样就提高速度了。

2.报文采取二进制格式。
HTTP2将所有传输的信息分割为更小的信息和帧，并采取二进制编码，服务器可以直接解析二进制报文，增加了数据的传输效率。
每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装，这也是多路复用同时发送数据的实现条件

3.多路复用
一个连接可以并发发送多个请求和响应，也不用按照顺序一一对应。这样就不会出现队头阻塞情况，大幅度降低了延迟，提高了连接的利用率。

4.服务器推送技术
HTTP2在一定程度上改善了传统的请求应答模式，服务器不再是被动接收信息，它能够预测主请求所需的依赖资源，响应主请求的同时，主动把依赖资源推送给客户端。客户端解析主请求响应后，可以从本地缓存直接获取依赖资源, 减少访问延时, 也加大了链路的并发能力。（举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端）

HTTP2主要问题在于多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求
的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等
待这个丢了的包被重传回来。
HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了
HTTP/2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部重传问题。
⼤家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。
QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到
影响。
TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。
HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把
以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

## 21.HTTP协议有什么特点？
+ 简单，快速。HTTP报文格式是header+body，同时头部也是key-value的形式，容易理解，使用起来只需指定请求的方法和路径即可，使用简单。
+ 灵活易于拓展：HTTP允许传输任意类型的数据，（content-type)标记，同时请求方法、状态码、URL、头部字段允许开发人员自定义拓充。HTTPS就是在HTTP和TCP之间增加了SSL/TLS安全传输层。
+ 无状态。
  + 好处：服务器不用记录HTTP状态，不需要额外的资源来记录状态信息，减轻服务器负担。
  + 坏处：由于没有记录状态，所以对事物处理没有记忆能力，比如说访问一个网站可能需要重复登陆
+ 基于请求响应机制，客户端发起请求，服务端响应
+ 不安全
  + 通信使用明文，内容可能被窃听。
  + 不验证通信双方的身份，可能遭遇伪装。
  + 无法证明报文的完整性，消息可能已经遭遇篡改。

## 22.HTTP方法有哪些？
1. GET：获取资源，当前⽹络中绝大部分使用的都是 GET；
2. HEAD：获取报⽂文⾸首部，和 GET ⽅方法类似，但是不返回报⽂实体主体部分；
3. POST：传输实体主体
4. PUT：上传文件，由于⾃身不不带验证机制，任何⼈都可以上传文件，因此存在安全性问题，⼀般不不使用该⽅
法。
5. delete：删除文件
6. Options:查询针对请求URL指定的资源支持的方法。

## 23.HTTP与HTTPS的区别？
+ 安全性：HTTP协议是明文传输，存在安全风险问题。而HTTPS是由SSL/TLS	协议构建的可进行加密、身份认证的协议，比HTTP安全。
+ 握手情况：HTTP连接更为简单，只需要TCP三次握手后即可传HTTP报文。HTTPS要在三次握手后进行SSL/TLS握手过程，才可加密处理，消耗的资源更多。
+ 端口不同：HTTP连接使用的是80端口，HTTPS是443端口。
+ HTTPS需要向CA申请数字证书，来保证服务器身份是可信的。

## 24.HTTPS针对解决HTTP问题
HTTP安全上有三个风险：
  + 通信使用明文，内容可能被窃听。
  + 不验证通信双方的身份，可能遭遇伪装。
  + 无法证明报文的完整性，消息可能已经遭遇篡改。(植入广告)


## 25.HTTPS解决三个风险的方法：

**混合加密**：
  + 在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。
  + 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。
   
采⽤「混合加密」的⽅式的原因：
+ 对称加密（DES，3DES，AES）只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。
+ ⾮对称加密（RSA）使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度慢。


**摘要算法**（MD5）：
  客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发
送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出
的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。

## 26.什么是数字签名（非对称加密）？
为了避免数据在传输过程中被篡改，发送端做一个数字签名，用摘要算法对数据生成摘要后用私钥加密，得到一个签名，接收端先用公钥解密签名得到摘要，再用同样的算法算出摘要，如果摘要一样就是真的。

## 27.什么是数字证书？
对称加密中，双⽅使⽤公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥
也被替换，则仍然可以伪造数据。为了了保证发送方的公钥是真
的，或者说为了验证网络中的身份。CA 证书机构会负责颁发一个证书，⾥面的公钥保证是真的，⽤户请求服务器时，服务器将证书发给⽤户，这
个证书是经由系统内置证书的备案的。

## 28.CA证书
目的：CA证书是为了确保服务端的公钥是准确无误，没被修改过的
证书通常包含这些内容(1) 服务端的公钥；(2) 证书发行者(CA)对证书的数字签名；(3) 证书所用的签名算法；(4) 证书发布机构、有效期、所有者的信息等其他信息


**CA签发：**
  + 服务方S 向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证；
  + CA将持有者公钥、用途、颁发者、有效时间等信息打包成一个包，同时用摘要算法对信息进行计算，得到一个hash值，CA用自己的私钥对该hash值加密，生成数字签名并将数字签名添加到文件证书上，形成数字证书。（证书上有服务器公钥 + 数字签名 + 申请者颁发者信息， 证书合法性依赖于非对称性加密。）


**客户端校验**：
  + 客户端向服务器S发出请求时，S返回证书文件。
  + 客户端使用同样的摘要算法获取该证书的hash值H1。
  + 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 数字签名 内容，得到一个 Hash 值 H2 。
  + 比较H1和H2，相同则证书可信。

## 29.D5、SHA、Base64和RSA属于什么类型的算法，对称还是非对称？
MD5、SHA，称为摘要算法，可以归类为单向加密算法，其计算出的摘要信息，是不可逆向恢复成原来的数据
RSA属于非对称加密算法
而Base64并不算是加密算法，它更多时候是被称为一种数据编码方式


## 30.https的流程
[![bZLtrq.png](https://s4.ax1x.com/2022/02/26/bZLtrq.png)](https://imgtu.com/i/bZLtrq)
+ TCP三次握手
  **SSL/TLS协议建立**
+ 首先由客户端向服务器发起加密通信请求，即ClientHello，发送客户端支持的TLS协议版本，产生的随即数c1,客户端支持的密码套件列表（RSA加密算法等）。
+ 服务器收到后，返回ACK响应，ServerHello请求，确认SSL/TLS协议版本，服务器产生的随机数c2,确认的密码套件列表。服务器数字证书还有一个serverHello Done请求。
+ 客户端收到服务器响应后，首先通过浏览器的CA公钥(CA校验流程)，确认数字证书的真实性。证书没问题后，从证书里取出服务器公钥，生成第三个随即数：预主密钥并用服务器公钥加密该随机数。然后他会发送以下东西
  （1）加密后的随机数、（2）加密通信算法改变通知，就是说之后采取会话密钥加密通信。（3）还有客户端握手结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘
要，⽤来供服务端校验。
+ 服务器收到消息后，用私钥解密出第三个随机数后，此时双方都有3个随机数，客户端和服务端利用这三个随机数计算出会话密钥。服务器会发送最后的消息。
  （1）一个是加密算法改变通知，表示随后的消息都会用会话密钥加密。
  （2）一个是服务器握手结束通知。表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供客户端校验。

⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP
协议，只不过⽤「会话秘钥」加密内容。                                                                           
## 30.网络抓包
在linux系统可以使用tcpdump命令对tcp请求数据抓包，抓到的数据输出到一个文件；然后可以在window使用wireshark软件加载tcp数据文件，它可以提供界面分析


## 31.在浏览器中输入URL后，执行的过程？
1.浏览器通过DNS解析获取域名对应的IP地址。
2.获取IP地址后，向服务器发起TCP连接（三次握手）
3.TCP连接建立后，向服务器发送HTTP请求。
4.服务器处理请求并返回HTTP报文：服务器接收到该请求，根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应视图返回给浏览器。
5.根据情况是否关闭TCP连接（四次挥手）。
6.浏览器解析HTML文档。
+ 通过解析HTML，生成DOM树。
+ 解析CSS，生成CSS规则树，
+ 通过DOM树和CSS规则树生成渲染树。
7.浏览器布局渲染。根据渲染树布局，计算CSS样式，即每个节点在页面中的大小和位置等几何信息。最后浏览器绘制各个节点，将页面展示给用户。

## 32.cookie和session
+ cookie
http是无状态的协议，所以服务器无法标识特定的客户，cookie可以看成是服务器标识特定客户的机制，是由服务器发给客户端的用于标识客户的个人信息，这些信息存放在客户端。每次客户端向服务器发送请求的时候请求头都会带上cookie，服务器收到客户端请求时，可以通过cookie得到客户端特有的信息，然后动态生成和该客户端有关的内容。

+ session
Session是在无状态的HTTP协议下，服务端记录用户状态时用于标识具体用户的机制。它是在服务端保存的用来跟踪用户的状态的数据结构，可以保存在文件、数据库或者集群中。浏览器访问web站点时，服务器首先会检查该客户端请求是否包含了一个session标识，也就是session id，假如有的话，就根据这个id提取session，否则就会在服务器为该客户端创建一个session并且将sessionid存放到cookie中，这个sessionid会在本次响应中返回到客户端保存，这样每次浏览器请求的时候都会带着这个session。（禁用cookie的时候采用url重写技术，sid = xxx)

区别：
1、Cookie 在客户端（浏览器），Session 在服务器端。

2、Cookie的安全性一般，他人可通过分析存放在本地的Cookie并进行Cookie欺骗。在安全性第一的前提下，选择Session更优。重要交互信息比如权限等就要放在Session中，一般的信息记录放Cookie就好了。

3、单个Cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个Cookie。

4、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie。

5、Session 的运行依赖Session ID，而 Session ID 是存在 Cookie 中的，也就是说，如果浏览器禁用了 Cookie，Session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 Session ID）。

6、用户验证这种场合一般会用 Session。因此，维持一个会话的核心就是客户端的唯一标识，即Session ID。

## 31.什么是对称加密和非对称加密？
对称加密：通信双方使用相同的密钥进行加密。特点是加密速度快，但是缺点是密钥泄露会导致密文数据被破解。常见的对称加密有AES和DES算法。

非对称加密：它需要生成两个密钥，公钥和私钥。公钥是公开的，任何人都可以获得，而私钥是私人保管的。公钥负责加密，私钥负责解密；或者私钥负责加密，公钥负责解密。这种加密算法安全性更高，但是计算量相比对称加密大很多，所以加密和解密都很慢。常见的非对称算法有RSA和DSA。

## 32.网络字节序？
大端：高位字节存放在低位地址
小端：高位字节存放在高位地址

网络字节序是TCP/IP中规定好的一种数据表示格式，它与具体的CPU类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释。网络字节序采用big endian排序方式。
所以socket填充前要转换。

SoftTrain
后端开发
+基于vue.js和fastapi开发的web端宿舍管理系统，用于存储处理宿舍相关业务
使用python fastapi框架实现后端
完成鉴权与数据库操作